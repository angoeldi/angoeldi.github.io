<html>
  <head>
    <title>My HTML File</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <h1>Welcome to my HTML file!</h1>
    <div>
      <label for="input">Input:</label>
      <input type="text" id="input" name="input">
      <button id="button">Generate Output</button>
    </div>
    <div id="output"></div>
    <script src="https://unpkg.com/node-fetch@4.0.0-beta.4/src/index.js"></script>
    <script src="secret.js"></script>
    <script src="https://huggingface.co/transformers/main-api.js"></script>
    <script>
      import fetch from "node-fetch";
      async function query(data) {
      const response = await fetch(
        "https://api-inference.huggingface.co/models/microsoft/GODEL-v1_1-large-seq2seq",
          {
            headers: { Authorization: `Bearer ${secret}` },
            method: "POST",
            body: JSON.stringify(data),
          }
      );
    const result = await response.json();
    return result;
}     
      // Get the API key from the api-key.js file
      const apiKey = require("./secret.js");

      // Load the model and tokenizer
      const model = new transformers.TFSeq2SeqModel("microsoft/GODEL-v1_1-large-seq2seq");
      const tokenizer = new transformers.HFTokenizer("microsoft/GODEL-v1_1-large-seq2seq");

      // Wait for the model and tokenizer to be ready
      Promise.all([model.ready(), tokenizer.ready()]).then(function() {
        console.log("Model and tokenizer are ready!");

        // Get a reference to the button and input field
        const button = document.getElementById("button");
        const inputField = document.getElementById("input");

        // Define the context (instruction, knowledge, and dialogue history)
        const context = "Please give me some information about yourself.";

        // Add an event listener to the button to handle clicks
        button.addEventListener("click", function() {
          // Get the input text from the input field
          const inputText = inputField.value;
          
          .then((response) => {
              console.log(JSON.stringify(response));
          });
          // Tokenize the input text and context
          // const inputTokens = tokenizer.encode(inputText, context);
          // Send the input to the model and receive the model's prediction as output
          //model.predict(inputTokens).then(function(output) {
          //  console.log("Model prediction:", output);
            // Decode the output tokens and create a text node containing the output text
          //  const outputText = tokenizer.decode(output, skipSpecialTokens=true);
            const textNode = document.createTextNode(response);

            // Add the text node to the output element in the HTML document
            const outputElement = document.getElementById("output");
            outputElement.appendChild(textNode);
          });
        });
      });
    </script>
  </body>
</html>
